{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7202d9f3-939c-43f0-8acc-8e6b9d0c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'transformers[torch]'\n",
    "# pip install pillow\n",
    "# pip install sentencepiece\n",
    "# pip install torchvision\n",
    "# pip install datasets\n",
    "# pip install scipy\n",
    "# pip install torchvision\n",
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedf6a1d-acc2-41cc-9c55-d413d1f840cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoProcessor, SpeechT5ForTextToSpeech\n",
    "from transformers import SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624104a7-b1c0-4cf0-b696-904f93b17bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/1z7t7vR.jpg\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=url, width=400, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2066d30-3146-4e9c-9d66-b07d6c6d36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://i.imgur.com/1z7t7vR.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95226503-eb7f-4a20-8ea4-9954361e2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://i.imgur.com/pyCnc.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1246dbcb-42a7-4010-abda-b1c588542e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'http://i.imgur.com/FIf0r.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62326f59-fd1b-4638-bac4-203540caedef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/home/wjkoh005/.local/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image2text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212094ae-e402-4eb9-af4c-042ffc20acd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a cloudy sky with a street light and a building '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48f7a0d-73dd-4467-a5a3-80944bed95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a dump truck is parked in a field '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url2, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cefc8f5-8fe8-46b0-b085-2e8ca5199bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a river with a waterfall and trees '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url3, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02861c04-e17f-4927-8bc9-ee920631cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = image2text(url, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3a442-bfc4-4a37-8d75-87ba3b0b50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing microsoft/speecht5_tts\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b79c4-4d4c-4879-ae30-9b0878c04edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872abf41-73d6-43be-a923-5194404c1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Speaker embedding\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee600f6-f9a8-4eea-8bd6-148e8d9baa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2636664-da96-4325-b0bb-9287816e2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vocoder\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7efc1-19db-45bf-bb4b-a124deb3303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    speech = vocoder(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff35186-6ce9-4e88-8b62-be2b00f2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca68b74-4935-48bc-ba27-0d34e56c743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adde22-2315-45b9-bfbc-8bf5e7d3569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(speech, rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
