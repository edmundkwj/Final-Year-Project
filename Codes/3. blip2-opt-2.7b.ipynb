{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7202d9f3-939c-43f0-8acc-8e6b9d0c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'transformers[torch]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4abb6a-2c62-4552-99f7-7865d07e22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b4e8d1-efb2-45ba-81b9-b891e0713556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'transformers[torch]'\n",
    "# pip install pillow\n",
    "# pip install sentencepiece\n",
    "# pip install torchvision\n",
    "# pip install datasets\n",
    "# pip install scipy\n",
    "# pip install torchvision\n",
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cedf6a1d-acc2-41cc-9c55-d413d1f840cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoProcessor, SpeechT5ForTextToSpeech\n",
    "from transformers import SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3104a514-6ae5-452f-bb4c-3c8c15e0aa1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://i.imgur.com/FIf0r.jpg\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://i.imgur.com/FIf0r.jpg' , width=400, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2066d30-3146-4e9c-9d66-b07d6c6d36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://i.imgur.com/1z7t7vR.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e43c9c-fcd2-47ea-ade7-fbc84b641b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://i.imgur.com/pyCnc.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976e4c31-0f45-4db8-8cbd-cc819a87a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'http://i.imgur.com/FIf0r.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6763892a-9425-4384-be9f-7b26fb0f52c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d1f6a6e91b432bb082d45cdf4e74ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image2text = pipeline(\"image-to-text\", model=\"Salesforce/blip2-opt-2.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212094ae-e402-4eb9-af4c-042ffc20acd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a storm is seen over a field with a tower in the background\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c606f68-7e14-4423-b466-330c959757a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a truck with a pile of wood on it\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url2, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b70d9e-a4ce-431c-aab6-4946239775ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a bench sitting in the middle of a waterfall\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2text(url3, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02861c04-e17f-4927-8bc9-ee920631cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = image2text(url, max_new_tokens=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3a442-bfc4-4a37-8d75-87ba3b0b50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing microsoft/speecht5_tts\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b79c4-4d4c-4879-ae30-9b0878c04edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872abf41-73d6-43be-a923-5194404c1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Speaker embedding\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee600f6-f9a8-4eea-8bd6-148e8d9baa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2636664-da96-4325-b0bb-9287816e2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vocoder\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7efc1-19db-45bf-bb4b-a124deb3303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    speech = vocoder(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff35186-6ce9-4e88-8b62-be2b00f2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca68b74-4935-48bc-ba27-0d34e56c743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adde22-2315-45b9-bfbc-8bf5e7d3569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(speech, rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
